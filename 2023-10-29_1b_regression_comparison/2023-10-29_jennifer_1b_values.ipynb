{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date: 2023-10-29\n",
    "### Author: Jennifer Fortuny I Zhan\n",
    "### Content: Project 2 Regression, Values for Linear Regression\n",
    "\n",
    "In this analysis, we extend a basic linear regression model to include Ridge regularization for predicting income levels based on selected features.\n",
    "\n",
    "We use a two-level cross-validation approach to optimize the regularization parameter lambda, aiming to minimize the error in each fold of the outerloop.\n",
    "\n",
    "The process ends in identifying the best lambda values and corresponding test errors, which are important for evaluating the model.\n",
    "\n",
    "Overall workflow:\n",
    "1. Loading the pre-processed data, for dependent and independent variables of both training and testing sets.\n",
    "2. Initialising the variables by setting up the number of folds for the outer and inner loops, i.e. K1 and K2, also initialised an empty array for potential lambda values.\n",
    "3. Two-level cross-validation was implemented by:\n",
    "    - An outer loop which partitioned the data into a training set ad test sets.\n",
    "    - An inner loop which further partitioned the trainning set into inner training and validation sets.\n",
    "    - Training the model and calculating the error. By using Ridge regression models on the inner trainning set for each lambda, and calculating the validation error.\n",
    "    - Selecting the best lambda by selecting the lambda that minimised the average validation error for each fold in the outerloop.\n",
    "    - Testing the error calculation E^test, for each fold in the outer loop, using the best lambda.\n",
    "4. Returning the best lambda values and E^test values for each fold, formated into 3 s.f."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data from CSV files\n",
    "dependent_test_df = pd.read_csv('../2023-10-05_jennifer_data_preparation/dependent_test.csv')\n",
    "dependent_train_df = pd.read_csv('../2023-10-05_jennifer_data_preparation/dependent_train.csv')\n",
    "independent_test_df = pd.read_csv('../2023-10-05_jennifer_data_preparation/independent_test.csv')\n",
    "independent_train_df = pd.read_csv('../2023-10-05_jennifer_data_preparation/independent_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converte DataFrames to NumPy arrays\n",
    "X = independent_train_df.values\n",
    "y = dependent_train_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Variables:\n",
    "# Number of folds for outer and inner loops\n",
    "K1 = 10\n",
    "K2 = 10\n",
    "\n",
    "# Lambda values to test\n",
    "lambdas = np.logspace(-4, 4, 50)\n",
    "\n",
    "# Empty list to store best lambda values for each fold\n",
    "best_lambdas = []\n",
    "E_test_values = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate error\n",
    "def calculate_error(y_true, y_pred):\n",
    "    N_test = len(y_true)\n",
    "    return (1 / N_test) * np.sum((y_true - y_pred)**2)\n",
    "\n",
    "# Outer Loop\n",
    "kf1 = KFold(n_splits=K1)\n",
    "for train_index, test_index in kf1.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # Initialize a list to store the average errors for each lambda value\n",
    "    avg_errors = np.zeros(len(lambdas))\n",
    "\n",
    "    # Inner Loop\n",
    "    kf2 = KFold(n_splits=K2)\n",
    "    errors = []  # Reset errors list for each outerloop\n",
    "    for inner_train_index, val_index in kf2.split(X_train):\n",
    "        X_inner_train, X_val = X_train[inner_train_index], X_train[val_index]\n",
    "        y_inner_train, y_val = y_train[inner_train_index], y_train[val_index]\n",
    "\n",
    "        # Train Models and Calculate Errors\n",
    "        for idx, l in enumerate(lambdas):\n",
    "            model = Ridge(alpha=l)  # This adds the regularzation term.\n",
    "            model.fit(X_inner_train, y_inner_train)\n",
    "            y_pred = model.predict(X_val)\n",
    "            error = calculate_error(y_val, y_pred)\n",
    "            avg_errors[idx] += error  # This accumilates the erros for each lambda\n",
    "\n",
    "    # Calculate the average errors for each lambda\n",
    "    avg_errors /= K2\n",
    "    \n",
    "    # Select Best Lambda\n",
    "    best_lambda = lambdas[np.argmin(avg_errors)]\n",
    "    best_lambdas.append(best_lambda)\n",
    "\n",
    "    # Train the best model on the entire training partition and calculate E^test\n",
    "    best_model = Ridge(alpha=best_lambda)\n",
    "    best_model.fit(X_train, y_train)\n",
    "    y_test_pred = best_model.predict(X_test)\n",
    "    E_test = calculate_error(y_test, y_test_pred)\n",
    "    E_test_values.append(E_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Lambda values for each fold in Linear Regression Model: ['16.768', '35.565', '35.565', '35.565', '35.565', '24.421', '24.421', '35.565', '35.565', '24.421']\n",
      "E^test values for each fold: ['0.155', '0.102', '0.205', '0.176', '0.103', '0.140', '0.155', '0.153', '0.182', '0.144']\n"
     ]
    }
   ],
   "source": [
    "# Output the best lambda values and E^test values for each fold\n",
    "print(\"Best Lambda values for each fold in Linear Regression Model:\", [f'{x:.3f}' for x in best_lambdas])\n",
    "print(\"E^test values for each fold:\", [f'{x:.3f}' for x in E_test_values])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('MachineLearningExer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "12a2eb8910076d8c1464a47385b72d672ab5a774af64507e171042e372c532da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
