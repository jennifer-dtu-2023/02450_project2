{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Two-levels cross-validation for ANN model<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow our project description two-level cross-validation, \n",
    "- Outer fold should be separated to train dataset and test dataset.\n",
    "- Inner fold training datasets should be divided to training and validation sets.\n",
    "- In inner fold, we should select the best hidden units to minimize the average validatation errors.\n",
    "- As we have already selected the best hidden units in each group, then compare each other by calculating the Generalization in outer fold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataframe from the csv files we stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.read_csv(\"/Users/luchengliang/02450_project2/2023-10-05_jennifer_data_preparation/independent_train.csv\")\n",
    "train_y = pd.read_csv(\"/Users/luchengliang/02450_project2/2023-10-05_jennifer_data_preparation/dependent_train.csv\")\n",
    "test_x = pd.read_csv(\"/Users/luchengliang/02450_project2/2023-10-05_jennifer_data_preparation/independent_test.csv\")\n",
    "test_y = pd.read_csv(\"/Users/luchengliang/02450_project2/2023-10-05_jennifer_data_preparation/dependent_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To clarify if we used the GPUs (Mac will choose mps and Windows will choose cuda for GPUs) or CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN_Model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_hidden_layers):\n",
    "        super(ANN_Model, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.input_layer = nn.Linear(self.input_dim, self.hidden_dim)\n",
    "        self.hidden_layers = nn.ModuleList([\n",
    "            nn.Linear(self.hidden_dim, self.hidden_dim) for _ in range(self.num_hidden_layers)\n",
    "        ])\n",
    "        self.output_layer = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dim, 1), \n",
    "            nn.Sigmoid()  \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for layer in self.hidden_layers:\n",
    "            x = torch.relu(layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights needed to be reset in each fold. The following function will reset the parameters of the model. It could ensure the model is trained with the initailized randomly weights in order to avoid weight leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(m):\n",
    "    for layer in m.children():\n",
    "        if hasattr(layer, 'reset_parameters'):\n",
    "            print(f'Reset trainable parameters of layer = {layer}')\n",
    "            layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11be1f470>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_x\n",
    "y = train_y\n",
    "\n",
    "K1 = 10\n",
    "K2 = 10\n",
    "kfold_1 = KFold(n_splits=K1, shuffle=True)\n",
    "kfold_2 = KFold(n_splits=K2, shuffle=True)\n",
    "\n",
    "num_epochs = 30\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "hidden_dim_list = [1, 2, 3, 4, 5, 6, 7,  8, 9, 10]\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Tenx = torch.Tensor(X.to_numpy())\n",
    "train_Teny = torch.Tensor(y.to_numpy())\n",
    "\n",
    "dataset = TensorDataset(train_Tenx, train_Teny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer_FOLD_out: 1\n",
      "--------------------------------\n",
      "Inner_FOLD_out: 1\n",
      "--------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ANN_Model.__init__() missing 3 required positional arguments: 'input_dim', 'hidden_dim', and 'num_hidden_layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m trainloader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m, sampler \u001b[39m=\u001b[39m train_subsampler)\n\u001b[1;32m     21\u001b[0m testloader \u001b[39m=\u001b[39m DataLoader(dataset, batch_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, sampler\u001b[39m=\u001b[39mtest_subsampler)\n\u001b[0;32m---> 23\u001b[0m model \u001b[39m=\u001b[39m ANN_Model()\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     25\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mSGD(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m0.001\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, num_epochs):\n",
      "\u001b[0;31mTypeError\u001b[0m: ANN_Model.__init__() missing 3 required positional arguments: 'input_dim', 'hidden_dim', and 'num_hidden_layers'"
     ]
    }
   ],
   "source": [
    "outer_generalization_errors_list = []\n",
    "best_hidden_units_list = []\n",
    "\n",
    "for fold, (train_ids_out, test_ids_out) in enumerate(kfold_1.split(dataset)):\n",
    "    \n",
    "    print(f'Outer_FOLD_out: {fold + 1}')\n",
    "    print('--------------------------------')\n",
    "    \n",
    "    inner_generalization_errors_list = []\n",
    "    \n",
    "    for inner_fold, (inner_train_ids_out, inner_test_ids_out) in enumerate(kfold_2.split(train_ids_out)):\n",
    "        \n",
    "        print(f'Inner_FOLD_out: {inner_fold + 1}')\n",
    "        print('--------------------------------')\n",
    "        inner_fold_errors = []\n",
    "        \n",
    "        train_subsampler = SubsetRandomSampler(inner_train_ids_out)\n",
    "        test_subsampler = SubsetRandomSampler(inner_test_ids_out)\n",
    "        \n",
    "        trainloader = DataLoader(dataset, batch_size = 10, sampler = train_subsampler)\n",
    "        testloader = DataLoader(dataset, batch_size=10, sampler=test_subsampler)\n",
    "        \n",
    "        model = ANN_Model().to(device)\n",
    "        \n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "        \n",
    "        for epoch in range(0, num_epochs):\n",
    "            \n",
    "            print(f'Starting epoch {epoch+1}')\n",
    "            \n",
    "            current_loss = 0.0\n",
    "            model.train()\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                \n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                current_loss += loss.item()\n",
    "                if i % 100 == 99:\n",
    "                    print('Loss after mini-batch %5d: %.3f' % (i+1, current_loss / 100))\n",
    "                    current_loss = 0.0\n",
    "        print('Inner fold training has finished.')\n",
    "        \n",
    "        print('Start testing')\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            squared_loss = 0\n",
    "            total_samples = 0\n",
    "            for i , data in enumerate(testloader, 0):\n",
    "                inputs, labels = data\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                squared_loss += ((outputs - labels)**2).sum().item()\n",
    "                total_samples += labels.size(0)\n",
    "            mse = squared_loss / total_samples\n",
    "            inner_fold_errors.append(mse)\n",
    "        inner_generalization_error = sum(inner_fold_errors) / len(inner_fold_errors)\n",
    "        inner_generalization_errors_list.append(inner_generalization_error)           \n",
    "    \n",
    "    #Chose the best model by the number of hidden units\n",
    "    \n",
    "    outer_fold_errors = []\n",
    "    \n",
    "    train_subsampler_out = SubsetRandomSampler(train_ids_out)\n",
    "    test_subsampler_out = SubsetRandomSampler(test_ids_out)\n",
    "    \n",
    "    trainloader_out = DataLoader(dataset, batch_size = 10, sampler = train_subsampler_out)\n",
    "    testloader_out = DataLoader(dataset, batch_size=10, sampler=test_subsampler_out)\n",
    "    \n",
    "    best_hidden_unit = hidden_dim_list[np.argmin(inner_generalization_errors_list)]\n",
    "    \n",
    "    best_model = ANN_Model().to(device)\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(0, num_epochs):\n",
    "        \n",
    "        print(f'Starting best model epoch {epoch+1}')\n",
    "        \n",
    "        current_loss = 0.0\n",
    "        model.train()\n",
    "        for i, data in enumerate(trainloader_out, 0):\n",
    "            \n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "            current_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('Loss after mini-batch %5d: %.3f' % (i+1, current_loss / 100))\n",
    "                current_loss = 0.0\n",
    "    print('Inner best model fold training has finished.')\n",
    "    \n",
    "    print('Start best model testing')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        squared_loss = 0\n",
    "        total_samples = 0\n",
    "        for i , data in enumerate(testloader_out, 0):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            squared_loss += ((outputs - labels)**2).sum().item()\n",
    "            total_samples += labels.size(0)\n",
    "        mse = squared_loss / total_samples\n",
    "        outer_fold_errors.append(mse)\n",
    "        \n",
    "    outer_generalization_error = sum(outer_fold_errors) / len(outer_fold_errors)\n",
    "    outer_generalization_errors_list.append(outer_generalization_error)\n",
    "    best_hidden_units_list.append(best_hidden_unit) \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best hidden units for each outer-fold in ANN Model:\", [f'{x:.3f}' for x in best_hidden_units_list])\n",
    "print(\"E^test values for each fold:\", [f'{x:.3f}' for x in outer_generalization_errors_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('MachineLearningExer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12a2eb8910076d8c1464a47385b72d672ab5a774af64507e171042e372c532da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
