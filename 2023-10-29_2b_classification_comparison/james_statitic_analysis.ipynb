{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "independent_train_df = pd.read_csv('../2023-10-05_jennifer_data_preparation/independent_train.csv')\n",
    "dependent_train_df = pd.read_csv('../2023-10-05_jennifer_data_preparation/dependent_train.csv')\n",
    "dependent_train_df = dependent_train_df.values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>3 models calculation for n_11, n_12, n_21, n_22 and the total<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model(train, test):\n",
    "    #Calaculate the most frequent appearance in the class (0, 1)\n",
    "    most_freq_class = np.bincount(train.flatten()).argmax()\n",
    "    predictions = np.full_like(test, most_freq_class)\n",
    "    \n",
    "    same_values_count = np.sum(predictions == test)\n",
    "    \n",
    "    total_elements = test.size\n",
    "    \n",
    "    return predictions, same_values_count, total_elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "e = 0\n",
    "t = np.array([1, 0, 0, 1, 0])\n",
    "y = np.array([0, 0, 1, 1, 1])\n",
    "u = np.array([1, 1, 1, 1, 1])\n",
    "\n",
    "e += np.sum((t == u) & (u != y))\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:33,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_1: 210\n",
      "n_1 percentage: 0.8203125\n",
      "n_1: 190\n",
      "n_1 percentage: 0.7421875\n",
      "n_1: 198\n",
      "n_1 percentage: 0.7734375\n",
      "n_11_LB: 182\n",
      "n_12_LB: 8\n",
      "n_21_LB: 16\n",
      "n_22_LB: 50\n",
      "n_11_CL: 166\n",
      "n_12_CL: 22\n",
      "n_21_CL: 24\n",
      "n_22_CL: 44\n",
      "n_11_CB: 166\n",
      "n_12_CB: 22\n",
      "n_21_CB: 32\n",
      "n_22_CB: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize variables\n",
    "K = 10  # Number of folds\n",
    "complexity_parameters = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=K)\n",
    "y_pred_number_CT = 0\n",
    "correct_number_CT = 0\n",
    "y_pred_number_logist = 0\n",
    "correct_number_logist = 0\n",
    "y_pred_number_base = 0\n",
    "correct_number_base = 0\n",
    "\n",
    "n_11_LB = 0\n",
    "n_12_LB = 0 \n",
    "n_21_LB = 0\n",
    "n_22_LB = 0\n",
    "n_11_CL = 0\n",
    "n_12_CL = 0 \n",
    "n_21_CL = 0\n",
    "n_22_CL = 0\n",
    "n_11_CB = 0\n",
    "n_12_CB = 0 \n",
    "n_21_CB = 0\n",
    "n_22_CB = 0\n",
    "\n",
    "\n",
    "\n",
    "for train_index, test_index in tqdm(kf.split(independent_train_df)):\n",
    "    X_train, X_test = independent_train_df.iloc[train_index], independent_train_df.iloc[test_index]\n",
    "    y_train, y_test = dependent_train_df[train_index], dependent_train_df[test_index]\n",
    "\n",
    "    \n",
    "    #CT_algorithm\n",
    "    best_correct = 0\n",
    "\n",
    "    for cp in complexity_parameters:\n",
    "        model = DecisionTreeClassifier(max_depth=cp)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        n_1 = sum(y_pred == y_test.ravel()) #james\n",
    "        \n",
    "        if n_1 > best_correct:    \n",
    "            best_correct = n_1\n",
    "\n",
    "    y_pred_number_CT += len(y_pred)\n",
    "    correct_number_CT += best_correct\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Logistic Regression\n",
    "    param_grid = {'C': np.logspace(-4, 4, 50)}\n",
    "    inner_model = LogisticRegression(max_iter=1000)\n",
    "    grid_search = GridSearchCV(inner_model, param_grid, cv=K, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Determine best lambda value\n",
    "    best_lambda = grid_search.best_params_\n",
    "    \n",
    "    # Train model with best lambda value\n",
    "    outer_model = LogisticRegression(max_iter=1000, **best_lambda)\n",
    "    outer_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    y_pred_outer = outer_model.predict(X_test)\n",
    "    y_pred_number_logist += len(y_pred_outer)\n",
    "    accuracy_outer = accuracy_score(y_test, y_pred_outer)\n",
    "    correct_number_logist += int(accuracy_outer*len(y_pred_outer))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Baseline \n",
    "    predictions, currect_number, total_number = baseline_model(y_train, y_test)\n",
    "    \n",
    "    y_pred_number_base += total_number\n",
    "    correct_number_base += currect_number\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Compare models - Logist v.s Baseline\n",
    "    n_11_LB += sum((y_pred_outer == y_test) & (predictions == y_test))\n",
    "    n_12_LB += sum((y_pred_outer == y_test) & (predictions != y_test))\n",
    "    n_21_LB += sum((y_pred_outer != y_test) & (predictions == y_test))\n",
    "    n_22_LB += sum((y_pred_outer != y_test) & (predictions != y_test))\n",
    "    \n",
    "    #Compare models - CT v.s Logist\n",
    "    n_11_CL += sum((y_pred == y_test) & (y_pred_outer == y_test))\n",
    "    n_12_CL += sum((y_pred == y_test) & (y_pred_outer != y_test))\n",
    "    n_21_CL += sum((y_pred != y_test) & (y_pred_outer == y_test))\n",
    "    n_22_CL += sum((y_pred != y_test) & (y_pred_outer != y_test))\n",
    "    \n",
    "    #Compare models - CT v.s Baseline\n",
    "    n_11_CB += sum((y_pred == y_test) & (predictions == y_test))\n",
    "    n_12_CB += sum((y_pred == y_test) & (predictions != y_test))\n",
    "    n_21_CB += sum((y_pred != y_test) & (predictions == y_test))\n",
    "    n_22_CB += sum((y_pred != y_test) & (predictions != y_test))\n",
    "    \n",
    "    \n",
    "print(\"n_1:\", correct_number_CT)\n",
    "print(\"n_1 percentage:\", correct_number_CT / y_pred_number_CT)\n",
    "print(\"n_1:\", correct_number_logist)\n",
    "print(\"n_1 percentage:\", correct_number_logist / y_pred_number_logist)\n",
    "print(\"n_1:\", correct_number_base)\n",
    "print(\"n_1 percentage:\", correct_number_base / y_pred_number_base)\n",
    "\n",
    "print(\"n_11_LB:\", n_11_LB)\n",
    "print(\"n_12_LB:\", n_12_LB)\n",
    "print(\"n_21_LB:\", n_21_LB)\n",
    "print(\"n_22_LB:\", n_22_LB)\n",
    "print(\"n_11_CL:\", n_11_CL)\n",
    "print(\"n_12_CL:\", n_12_CL)\n",
    "print(\"n_21_CL:\", n_21_CL)\n",
    "print(\"n_22_CL:\", n_22_CL)\n",
    "print(\"n_11_CB:\", n_11_CB)\n",
    "print(\"n_12_CB:\", n_12_CB)\n",
    "print(\"n_21_CB:\", n_21_CB)\n",
    "print(\"n_22_CB:\", n_22_CB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>McNerma Test<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def McNemar_t(n_11, n_12, n_21, n_22, n):\n",
    "    \n",
    "    confusion_matrix = [\n",
    "        [n_11, n_12],\n",
    "        [n_21, n_22]\n",
    "    ]\n",
    "    \n",
    "    # McNemar's test\n",
    "    result = mcnemar(confusion_matrix, exact=True)\n",
    "    \n",
    "    E_theta = (n_12 - n_21)/n\n",
    "    \n",
    "    # Calculate the confidence interval based on chi-squared distribution\n",
    "    alpha = 0.05  # significance level 95% CI\n",
    "    \n",
    "    # Find the critical values for the confidence interval\n",
    "    #theata_L_value = chi2_contingency(confusion_matrix, alpha / 2)[0]\n",
    "    #theata_U_value = chi2_contingency(confusion_matrix, 1 - alpha / 2)[0]\n",
    "\n",
    "    \n",
    "    # Calculate the confidence interval\n",
    "    #theata_L = 0.5 * (1 - np.sqrt(1 - theata_L_value / (n_11 + n_12)))\n",
    "    #theata_U = 0.5 * (1 + np.sqrt(1 - theata_U_value / (n_11 + n_12)))\n",
    "    \n",
    "    alpha = 0.05  # 95% CI\n",
    "    #Q = (n**2 * (n+1)*(E_theta + 1)*(1 - E_theta)) / (n*(n_12 + n_21) - (n_12 - n_21)**2)\n",
    "    #f = (E_theta+1)/2 * (Q - 1)\n",
    "    #g = (1 - E_theta)/2 * (Q - 1)\n",
    "    n_CI = n_11 + n_12  \n",
    "    p_CI = n_11 / n_CI\n",
    "    \n",
    "    theta_L = 2 * binom.ppf(alpha/2, n_CI, p_CI) / n_CI - 1\n",
    "    theta_U = 2 * binom.ppf(1 - alpha/2, n_CI, p_CI) / n_CI - 1\n",
    "    \n",
    "\n",
    "    print(\"McNemar's test statistic:\", result.statistic)\n",
    "    print(\"p-value:\", result.pvalue)\n",
    "    print(\"E_theata:\", E_theta)\n",
    "    print(f\"Confidence interval: ({theta_L}, {theta_U})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Compare Logistic Regression model and Baseline model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar's test statistic: 8.0\n",
      "p-value: 0.15158963203430176\n",
      "E_theata: -0.03125\n",
      "Confidence interval: (0.8526315789473684, 0.9684210526315788)\n"
     ]
    }
   ],
   "source": [
    "t = McNemar_t(n_11_LB, n_12_LB, n_21_LB, n_22_LB, 256)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Compare Classification Trees Values and Logistic Regression<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar's test statistic: 22.0\n",
      "p-value: 0.8829959121223965\n",
      "E_theata: -0.0078125\n",
      "Confidence interval: (0.6702127659574468, 0.8510638297872339)\n"
     ]
    }
   ],
   "source": [
    "t = McNemar_t(n_11_CL, n_12_CL, n_21_CL, n_22_CL, 256)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Compare Classification Trees Values and Baseline model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar's test statistic: 22.0\n",
      "p-value: 0.22032849417661093\n",
      "E_theata: -0.0390625\n",
      "Confidence interval: (0.6702127659574468, 0.8510638297872339)\n"
     ]
    }
   ],
   "source": [
    "t = McNemar_t(n_11_CB, n_12_CB, n_21_CB, n_22_CB, 256)\n",
    "t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('MachineLearningExer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12a2eb8910076d8c1464a47385b72d672ab5a774af64507e171042e372c532da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
