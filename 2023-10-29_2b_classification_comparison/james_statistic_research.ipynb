{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import binom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "Baseline_E = np.array([0.231, 0.231, 0.192, 0.308, 0.231, 0.115, 0.240, 0.280, 0.280, 0.160])\n",
    "Logistic_E = np.array([0.231, 0.192, 0.308, 0.346, 0.154, 0.231, 0.240, 0.280, 0.280, 0.320])\n",
    "CT_E = np.array([0.269, 0.115, 0.192, 0.231, 0.077, 0.154, 0.200, 0.200, 0.280, 0.120])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def McNemar_t(first_model, stardard_model, n):\n",
    "    \n",
    "    n_11 = sum((1 - first_model) + (1 - stardard_model))\n",
    "    n_12 = sum((1 - first_model) + stardard_model)\n",
    "    n_21 = sum(first_model + (1 - stardard_model))\n",
    "    n_22 = sum(first_model + stardard_model)\n",
    "    \n",
    "    confusion_matrix = [\n",
    "        [n_11, n_12],\n",
    "        [n_21, n_22]\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # Calculate the confidence interval based on chi-squared distribution\n",
    "    alpha = 0.05  # significance level 95% CI\n",
    "    \n",
    "    # Find the critical values for the confidence interval\n",
    "    #theata_L_value = chi2_contingency(confusion_matrix, alpha / 2)[0]\n",
    "    #theata_U_value = chi2_contingency(confusion_matrix, 1 - alpha / 2)[0]\n",
    "\n",
    "    \n",
    "    # Calculate the confidence interval\n",
    "    #theata_L = 0.5 * (1 - np.sqrt(1 - theata_L_value / (n_11 + n_12)))\n",
    "    #theata_U = 0.5 * (1 + np.sqrt(1 - theata_U_value / (n_11 + n_12)))\n",
    "    \n",
    "    # 设置二项分布的参数\n",
    "    n_CI = n_11 + n_12 # 总样本数\n",
    "    p_CI = n_11/n_CI   # 假设成功概率为0.5，这里可以根据实际情况调整\n",
    "\n",
    "    print(n_CI)\n",
    "    print(p_CI)\n",
    "    # 设置置信水平\n",
    "    alpha = 0.05  # 例如，95% 置信水平\n",
    "\n",
    "    # 计算置信区间的上下限\n",
    "    theta_L = 2 * binom.ppf(alpha/2, n_CI, p_CI) / n_CI - 1\n",
    "    theta_U = 2 * binom.ppf(1 - alpha/2, n_CI, p_CI) / n_CI - 1\n",
    "    print(theta_L)\n",
    "    # McNemar's test\n",
    "    result = mcnemar(confusion_matrix, exact=True)\n",
    "    \n",
    "    E_theta = (n_12 - n_21)/n\n",
    "\n",
    "    print(\"McNemar's test statistic:\", result.statistic)\n",
    "    print(\"p-value:\", result.pvalue)\n",
    "    print(\"E_theata:\", E_theta)\n",
    "    print(f\"Confidence interval: ({theta_L}, {theta_U})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Compare Baseline model and Logistic Regression model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.231 0.231 0.192 0.308 0.231 0.115 0.24  0.28  0.28  0.16 ]\n",
      "[0.231 0.192 0.308 0.346 0.154 0.231 0.24  0.28  0.28  0.32 ]\n"
     ]
    }
   ],
   "source": [
    "print(Baseline_E)\n",
    "print(Logistic_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.836\n",
      "0.6100016105653084\n",
      "nan\n",
      "McNemar's test statistic: 9.686\n",
      "p-value: 0.8238029479980469\n",
      "E_theata: -0.06280000000000001\n",
      "Confidence interval: (nan, nan)\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "McNemar_t(Logistic_E, Baseline_E, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Compare Logistic Regression  and Classification Trees Values<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.269 0.115 0.192 0.231 0.077 0.154 0.2   0.2   0.28  0.12 ]\n",
      "[0.231 0.192 0.308 0.346 0.154 0.231 0.24  0.28  0.28  0.32 ]\n"
     ]
    }
   ],
   "source": [
    "print(CT_E)\n",
    "print(Logistic_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.323999999999998\n",
      "0.5918553411335664\n",
      "nan\n",
      "McNemar's test statistic: 9.256\n",
      "p-value: 0.8238029479980469\n",
      "E_theata: 0.14879999999999996\n",
      "Confidence interval: (nan, nan)\n"
     ]
    }
   ],
   "source": [
    "# We use the Classification Trees  as a standard for Logistic Regression\n",
    "n = 10\n",
    "McNemar_t(CT_E, Logistic_E, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Compare Classification Trees Values and Baseline model<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.269 0.115 0.192 0.231 0.077 0.154 0.2   0.2   0.28  0.12 ]\n",
      "[0.231 0.231 0.192 0.308 0.231 0.115 0.24  0.28  0.28  0.16 ]\n"
     ]
    }
   ],
   "source": [
    "print(CT_E)\n",
    "print(Baseline_E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.323999999999998\n",
      "0.6037836195107127\n",
      "nan\n",
      "McNemar's test statistic: 9.57\n",
      "p-value: 0.8238029479980469\n",
      "E_theata: 0.08599999999999994\n",
      "Confidence interval: (nan, nan)\n"
     ]
    }
   ],
   "source": [
    "n = 10\n",
    "McNemar_t(CT_E, Baseline_E, n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('MachineLearningExer')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12a2eb8910076d8c1464a47385b72d672ab5a774af64507e171042e372c532da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
